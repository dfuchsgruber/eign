{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using EIGN's Laplacian and Convolution Operators\n",
    "\n",
    "Here, we will explore in further detail how to use the Laplacian operators and the associated convolutions to build your own model with EIGN's layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a dummy graph\n",
    "\n",
    "Let's create a dummy graph with some directed and undirected edges. We assign each edge with features that have an inherent direction (signed or orientation equivariant features) and some features that do not have an inherent direction (unsigned or orientation invariant features).\n",
    "\n",
    "The signed features are represented with respect to some arbitrary edge orientation through their sign. The edge orientation is encoded through the `edge_index`: If it contains an edge `(u, v)`, signed features are represented relative to the orientation `u -> v`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_signed_features = 3\n",
    "num_unsigned_features = 6\n",
    "\n",
    "# Represent the graph\n",
    "edge_index = (\n",
    "    torch.tensor(\n",
    "        [\n",
    "            [0, 1],\n",
    "            [1, 2],\n",
    "            [2, 3],\n",
    "            [2, 4],\n",
    "            [3, 5],\n",
    "            [5, 0],\n",
    "            [5, 2],\n",
    "        ]\n",
    "    )\n",
    "    .t()\n",
    "    .contiguous()\n",
    ")\n",
    "edge_is_directed = torch.tensor([0, 0, 0, 0, 0, 1, 1], dtype=torch.bool)\n",
    "\n",
    "dummy_features_signed = torch.randn(edge_index.size(1), num_signed_features)\n",
    "dummy_features_unsigned = torch.randn(edge_index.size(1), num_unsigned_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Magnetic Edge Laplacian\n",
    "\n",
    "Our code materializes the magnetic operators at the core of EIGN using sparse matrices to scale to large graphs. By introducing a phase shift, these operators are complex-valued."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from eign import magnetic_edge_laplacian, magnetic_incidence_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nfs/homedirs/fuchsgru/magnetic_edge_gnn/eign/src/eign/laplacian.py:112: UserWarning: Sparse CSR tensor support is in beta state. If you miss a functionality in the sparse tensor support, please submit a feature request to https://github.com/pytorch/pytorch/issues. (Triggered internally at ../aten/src/ATen/SparseCsrTensorImpl.cpp:53.)\n",
      "  laplacian = (\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(indices=tensor([[0, 0, 0, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 3, 3, 3, 3, 4, 4,\n",
       "                        4, 4, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6],\n",
       "                       [0, 1, 5, 0, 1, 2, 3, 6, 1, 2, 3, 4, 6, 1, 2, 3, 6, 2, 4,\n",
       "                        5, 6, 0, 4, 5, 6, 1, 2, 3, 4, 5, 6]]),\n",
       "       values=tensor([ 2.0000+0.0000j, -1.0000+0.0000j, -0.9010+0.4339j,\n",
       "                      -1.0000+0.0000j,  2.0000+0.0000j, -1.0000+0.0000j,\n",
       "                      -1.0000+0.0000j,  0.9010-0.4339j, -1.0000+0.0000j,\n",
       "                       2.0000+0.0000j,  1.0000+0.0000j, -1.0000+0.0000j,\n",
       "                      -0.9010+0.4339j, -1.0000+0.0000j,  1.0000+0.0000j,\n",
       "                       2.0000+0.0000j, -0.9010+0.4339j, -1.0000+0.0000j,\n",
       "                       2.0000+0.0000j, -0.9010-0.4339j, -0.9010-0.4339j,\n",
       "                      -0.9010-0.4339j, -0.9010+0.4339j,  2.0000+0.0000j,\n",
       "                       1.0000+0.0000j,  0.9010+0.4339j, -0.9010-0.4339j,\n",
       "                      -0.9010-0.4339j, -0.9010+0.4339j,  1.0000+0.0000j,\n",
       "                       2.0000+0.0000j]),\n",
       "       size=(7, 7), nnz=31, layout=torch.sparse_coo)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L_signed_to_signed = magnetic_edge_laplacian(\n",
    "    edge_index,\n",
    "    edge_is_directed,\n",
    "    q=1 / edge_index.size(1),\n",
    "    signed_in=True,\n",
    "    signed_out=True,\n",
    ")\n",
    "L_signed_to_unsigned = magnetic_edge_laplacian(\n",
    "    edge_index,\n",
    "    edge_is_directed,\n",
    "    q=1 / edge_index.size(1),\n",
    "    signed_in=True,\n",
    "    signed_out=False,\n",
    ")\n",
    "L_unsigned_to_signed = magnetic_edge_laplacian(\n",
    "    edge_index,\n",
    "    edge_is_directed,\n",
    "    q=1 / edge_index.size(1),\n",
    "    signed_in=False,\n",
    "    signed_out=True,\n",
    ")\n",
    "L_unsigned_to_unsigned = magnetic_edge_laplacian(\n",
    "    edge_index,\n",
    "    edge_is_directed,\n",
    "    q=1 / edge_index.size(1),\n",
    "    signed_in=False,\n",
    "    signed_out=False,\n",
    ")\n",
    "L_signed_to_signed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These operators can be used as (orientation equivariant / invariant) graph shift operator for edge signals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.3976-0.1484j,  2.0847-0.8242j, -1.3104+0.1457j,  0.0156-0.0762j,\n",
       "          0.4481-0.0593j,  0.2663+0.2147j],\n",
       "        [ 3.0569-0.4861j,  1.5729-0.1470j,  2.6326-0.7833j, -4.6981-0.1897j,\n",
       "         -0.6818-0.0484j, -1.0065-0.2472j],\n",
       "        [ 1.0951+0.4861j, -0.3666+0.1470j, -0.3548+0.7833j,  4.1013+0.1897j,\n",
       "          0.8220+0.0484j, -0.7784+0.2472j],\n",
       "        [-0.8543+0.4861j,  0.4231+0.1470j, -1.2198+0.7833j,  1.3796+0.1897j,\n",
       "         -1.4880+0.0484j, -1.2642+0.2472j],\n",
       "        [-0.8495+0.3377j, -0.3049-0.6773j,  1.3282+0.9291j,  1.8665+0.1135j,\n",
       "         -1.0853-0.0109j,  0.9206+0.4619j],\n",
       "        [-1.9271-1.1252j, -2.7543-0.2084j, -2.4082-0.0667j, -1.2403+1.0477j,\n",
       "          0.4268+1.0513j,  0.4315+0.2827j],\n",
       "        [-0.1568-0.9769j,  0.9626+0.5035j, -0.9403-0.0675j, -5.3437-1.2234j,\n",
       "          0.2630+0.8529j, -0.2212-0.0677j]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L_signed_to_signed @ dummy_features_signed.to(L_signed_to_signed.dtype)\n",
    "L_signed_to_unsigned @ dummy_features_signed.to(L_signed_to_unsigned.dtype)\n",
    "L_unsigned_to_unsigned @ dummy_features_unsigned.to(L_unsigned_to_unsigned.dtype)\n",
    "L_unsigned_to_signed @ dummy_features_unsigned.to(L_unsigned_to_signed.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Be mindful that for `q != 0`, these shift operators are complex-valued and so must their inputs. A convenient way to combine this with learnable feature transformations that operate on real values is to flatten and unflatten the edge signal. Effectively, we therefore model the real and complex part of the signals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([7, 16])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_signed_features_out = 16\n",
    "lin = nn.Linear(num_signed_features, num_signed_features_out)\n",
    "\n",
    "hidden_signed_complex = torch.view_as_complex(\n",
    "    lin(dummy_features_signed).reshape(-1, num_signed_features_out // 2, 2)\n",
    ")\n",
    "hidden_signed_complex = L_signed_to_signed @ hidden_signed_complex\n",
    "hidden_signed = torch.view_as_real(hidden_signed_complex).reshape(\n",
    "    -1, num_signed_features_out\n",
    ")\n",
    "hidden_signed.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Node-level signals\n",
    "\n",
    "The magnetic incidence matrices define mappings from edge signals to node signals and vice versa. This can be used to incorporate or predict node level outputs while still satisfying orientation equivariance or invariance.\n",
    "\n",
    "These node level signals are invariant to orientation changes of *undirected* edges. Therefore, any transformation (that does not depend on orientation) can be used to transform them, if desired (see `eign_example.ipynb`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "B_signed = magnetic_incidence_matrix(\n",
    "    edge_index, edge_is_directed, q=1 / edge_index.size(1), signed=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6, 16])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "node_level = B_signed @ hidden_signed.to(B_signed.dtype)\n",
    "node_level.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, the boundary operator can transform node level signals to the edge level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([7, 16])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "node_level = torch.randn(\n",
    "    int(edge_index.max().item()) + 1, num_signed_features_out, dtype=B_signed.dtype\n",
    ")\n",
    "edge_level = B_signed.conj().t() @ node_level\n",
    "edge_level.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Built-in Convolution operators\n",
    "\n",
    "The `eign` package also provides convolution operators that use these Laplacians. Each of these convolutions uses a single linear layer as an edge-feature transformation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from eign import (\n",
    "    MagneticEdgeLaplacianConv,\n",
    "    MagneticEdgeLaplacianWithNodeTransformationConv,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MagneticEdgeLaplacianConv(\n",
       "  (lin): Linear(in_features=3, out_features=16, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv = MagneticEdgeLaplacianConv(\n",
    "    num_signed_features,\n",
    "    num_signed_features_out,\n",
    "    q=1 / edge_index.size(1),\n",
    "    signed_in=True,\n",
    "    signed_out=True,\n",
    "    bias=None,  # Setting `bias` to `None` automatically uses a bias only if orientation equivariance / invariance is preserved\n",
    ").eval()\n",
    "conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 2.2376e-01,  2.3321e-01,  1.0154e-01,  4.4024e-01, -8.1171e-02,\n",
       "         -5.0108e-02,  1.6376e-01,  1.1127e-01,  4.1456e-01, -1.5332e-01,\n",
       "         -1.7078e-01,  9.4374e-02,  4.7508e-01,  2.7954e-01, -1.7467e-01,\n",
       "          3.1720e-01],\n",
       "        [-5.2929e-01, -5.4653e-01, -6.4605e-02, -5.0673e-01,  3.0910e-01,\n",
       "          1.0555e-01, -7.2847e-03, -2.9625e-01, -5.4794e-01,  3.0851e-01,\n",
       "          1.6006e-01, -9.4288e-02, -5.3793e-01, -4.2596e-01,  2.0172e-01,\n",
       "         -5.6020e-01],\n",
       "        [ 7.0587e-01,  6.9223e-01, -6.7022e-04,  4.0147e-01, -5.0969e-01,\n",
       "         -8.8372e-02,  8.3006e-02,  4.8430e-01,  4.0839e-01, -4.2072e-01,\n",
       "         -2.4215e-01,  1.7607e-01,  4.5952e-01,  4.1288e-01, -1.1597e-01,\n",
       "          5.6947e-01],\n",
       "        [ 7.5829e-01,  6.3479e-01,  8.3270e-02,  5.4759e-01, -4.3006e-01,\n",
       "         -8.5693e-02, -5.1941e-02,  3.8820e-01,  5.8925e-01, -4.2550e-01,\n",
       "         -1.2657e-01,  9.7673e-02,  6.1236e-01,  4.6654e-01, -1.6139e-01,\n",
       "          7.0615e-01],\n",
       "        [-3.7523e-01, -5.7703e-01, -3.2142e-03, -4.9500e-01,  3.0858e-01,\n",
       "          1.1719e-01, -2.9387e-01, -3.4930e-01, -4.6456e-01,  2.5432e-01,\n",
       "          3.6945e-01, -2.1743e-01, -5.0702e-01, -4.3553e-01,  2.4272e-01,\n",
       "         -4.0114e-01],\n",
       "        [ 9.3502e-02,  9.9188e-02,  1.8087e-01,  1.7098e-01, -3.1004e-02,\n",
       "         -4.0749e-02,  1.1760e-01, -7.7114e-02,  1.6972e-01, -1.6254e-01,\n",
       "         -5.2185e-02,  1.4062e-01,  2.8723e-01, -1.9778e-02, -4.6580e-02,\n",
       "          1.8233e-01],\n",
       "        [-6.7032e-02, -3.5244e-01,  2.2729e-01,  2.8998e-02,  1.5038e-01,\n",
       "          1.1702e-01,  2.8735e-01, -1.8572e-01, -1.0491e-01, -6.8587e-02,\n",
       "         -1.9985e-02,  1.1275e-01,  1.9703e-01, -2.4190e-01,  1.3093e-01,\n",
       "         -7.3411e-02]], grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv(dummy_features_signed, edge_index, edge_is_directed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also define your own node-level feature transformation. For example, you could inform the convolution about node features that are available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.4800, -0.0344,  0.0086,  0.1173,  0.3124,  0.2384, -0.3932,  0.2863,\n",
       "          0.0809, -0.4113,  0.0000,  0.1012, -0.4231,  0.0000, -0.1464, -0.6657],\n",
       "        [ 0.3667,  0.2890, -0.0189, -0.0958, -0.2551, -0.1947,  0.6252, -0.2338,\n",
       "         -0.0660,  0.1818,  0.3318,  0.1568,  0.0000,  0.0830,  0.0000,  0.5429],\n",
       "        [-0.2936, -0.1894,  0.0810,  0.0000,  0.0000,  0.0000, -0.6035,  0.0000,\n",
       "          0.1187, -0.1818, -0.2843, -0.2678,  0.1181, -0.0830,  0.0024, -0.3616],\n",
       "        [-0.2452, -0.2099,  0.0000,  0.3732,  0.5058,  0.1298, -0.5782,  0.0042,\n",
       "          0.3029,  0.0266, -0.3635,  0.2527,  0.0000, -0.0910,  0.2457,  0.0759],\n",
       "        [-0.1669,  0.1031,  0.1791,  0.3422,  0.0288,  0.0000,  0.2200,  0.0000,\n",
       "         -0.1300,  0.0000, -0.0521, -0.0124,  0.2042,  0.2851,  0.0960, -0.1985],\n",
       "        [ 0.3521,  0.0604, -0.3781, -0.1864, -0.0260,  0.0125,  0.0972,  0.2583,\n",
       "         -0.1596,  0.3314, -0.0188,  0.0391, -0.0833,  0.0521, -0.2292,  0.6361],\n",
       "        [ 0.1717,  0.2586, -0.3294, -0.1623, -0.0219,  0.0106,  0.3359,  0.3405,\n",
       "         -0.0730,  0.1516,  0.1647,  0.3661, -0.3919, -0.0255, -0.2931,  0.4890]],\n",
       "       grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class MyNodeTransformation(nn.Module):\n",
    "    def __init__(\n",
    "        self, num_features_in_edge, num_features_out_edge, num_features_in_node\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.edge_level = nn.Linear(num_features_in_edge, num_features_out_edge)\n",
    "        self.node_level = nn.Linear(num_features_in_node, num_features_out_edge)\n",
    "\n",
    "    def forward(self, edge_level, node_level):\n",
    "        return F.relu(self.edge_level(edge_level) + self.node_level(node_level))\n",
    "\n",
    "\n",
    "def initialize_node_feature_transformation(\n",
    "    in_channels: int, out_channels: int, num_features_in_node\n",
    ") -> nn.Module:\n",
    "    return MyNodeTransformation(in_channels, out_channels, num_features_in_node)\n",
    "\n",
    "\n",
    "conv = MagneticEdgeLaplacianWithNodeTransformationConv(\n",
    "    num_signed_features,\n",
    "    num_signed_features_out,\n",
    "    q=1 / edge_index.size(1),\n",
    "    signed_in=True,\n",
    "    signed_out=True,\n",
    "    initialize_node_feature_transformation=initialize_node_feature_transformation,\n",
    "    # Additional args and kwargs are passed to `initialize_node_feature_transformation`\n",
    "    num_features_in_node=13,\n",
    ").eval()\n",
    "\n",
    "node_level_signal = torch.randn(int(edge_index.max().item()) + 1, 13)\n",
    "conv(\n",
    "    dummy_features_signed,\n",
    "    edge_index,\n",
    "    edge_is_directed,\n",
    "    # Additional args and kwargs are passed to `initialize_node_feature_transformation.forward`\n",
    "    node_level_signal,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using EIGN Blocks\n",
    "\n",
    "One block of EIGN uses convolutions and a fusion layer to model local interactions. This is also encapsulated in a block class that can be used if so desired."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from eign import (\n",
    "    EIGNBlockMagneticEdgeLaplacianConv,\n",
    "    EIGNBlockMagneticEdgeLaplacianWithNodeTransformationConv,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_unsigned_features_out = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EIGNBlockMagneticEdgeLaplacianConv(\n",
       "  (signed_fusion_layer): FusionLayer(\n",
       "    (lin_layer1): Linear(in_features=16, out_features=16, bias=False)\n",
       "    (lin_layer2): Linear(in_features=16, out_features=16, bias=False)\n",
       "  )\n",
       "  (unsigned_fusion_layer): FusionLayer(\n",
       "    (lin_layer1): Linear(in_features=16, out_features=16, bias=True)\n",
       "    (lin_layer2): Linear(in_features=16, out_features=16, bias=True)\n",
       "  )\n",
       "  (unsigned_conv): ResidualWrapper(\n",
       "    (lin): Linear(in_features=6, out_features=16, bias=False)\n",
       "    (conv): MagneticEdgeLaplacianConv(\n",
       "      (lin): Linear(in_features=6, out_features=16, bias=False)\n",
       "    )\n",
       "  )\n",
       "  (unsigned_signed_conv): MagneticEdgeLaplacianConv(\n",
       "    (lin): Linear(in_features=6, out_features=16, bias=False)\n",
       "  )\n",
       "  (signed_conv): ResidualWrapper(\n",
       "    (lin): Linear(in_features=3, out_features=16, bias=False)\n",
       "    (conv): MagneticEdgeLaplacianConv(\n",
       "      (lin): Linear(in_features=3, out_features=16, bias=False)\n",
       "    )\n",
       "  )\n",
       "  (signed_unsigned_conv): MagneticEdgeLaplacianConv(\n",
       "    (lin): Linear(in_features=3, out_features=16, bias=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "block = EIGNBlockMagneticEdgeLaplacianConv(\n",
    "    num_signed_features,\n",
    "    num_signed_features_out,\n",
    "    num_unsigned_features,\n",
    "    num_unsigned_features_out,\n",
    "    q=1 / edge_index.size(1),\n",
    ").eval()\n",
    "block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_signed, output_unsigned = block(\n",
    "    dummy_features_signed, dummy_features_unsigned, edge_index, edge_is_directed\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.3581,  0.2057,  0.4567, -0.3503,  0.5559, -0.1147,  0.3204,  0.1869,\n",
       "         -0.3732, -0.1508, -0.6672, -0.4099,  0.8753, -0.4462, -0.2957, -0.5566],\n",
       "        [-0.2667,  0.5258, -0.3243, -0.5295, -0.2900, -0.7422, -0.6942,  0.1552,\n",
       "         -0.6747, -0.0857,  0.3551, -0.9293,  0.6151, -0.8680,  0.5882, -0.4349],\n",
       "        [ 0.2575,  0.1130, -0.3635,  0.4356, -0.8739,  0.1601, -0.1613, -0.4904,\n",
       "         -0.1907, -0.6528,  0.6595,  0.2372,  0.2861,  0.8399,  0.0780,  0.4730],\n",
       "        [ 0.6064, -0.9089,  0.4926,  0.3841,  0.6003,  1.0251,  0.9099, -0.3473,\n",
       "          0.8668,  0.6405, -0.5512,  0.8687, -0.8110,  0.7201, -0.6522,  0.4163],\n",
       "        [-0.7042,  0.9108, -0.7157,  0.4774, -0.9342, -0.1898, -0.8767, -0.7547,\n",
       "         -0.8977, -0.4987,  0.9212, -0.3779,  0.8107, -0.4205,  0.4524, -0.5124],\n",
       "        [ 0.7462,  0.6828, -0.0820, -0.8530, -0.4785, -0.4315, -0.6103,  0.4677,\n",
       "         -0.7656, -0.7704, -0.5445, -0.8427,  0.8008, -0.5492,  0.3564, -0.3676],\n",
       "        [-0.1096, -0.4446, -0.1564, -0.3179,  0.6795,  0.4247,  0.1943,  0.2304,\n",
       "          0.6037,  0.7449, -0.4687,  0.3933, -0.5786, -0.2908, -0.2095,  0.4701]],\n",
       "       grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_signed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 2.6522e-01,  4.0882e-01,  1.0961e+00,  2.7800e-01, -3.1668e-02,\n",
       "          3.1696e-01, -2.2765e-03,  2.8104e-01,  1.4925e+00,  7.5996e-01,\n",
       "         -7.7084e-02,  1.0134e+00,  7.2478e-01,  3.6854e-02,  4.3876e-02,\n",
       "         -1.0827e-02],\n",
       "        [-2.8249e-02, -1.2893e-02,  1.2853e+00,  6.9410e-01,  4.9405e-04,\n",
       "          1.3311e-02,  2.4489e-02, -1.5311e-01,  7.5778e-01,  1.1511e+00,\n",
       "         -1.4159e-01,  2.0968e-01,  4.2797e-01,  2.2610e-02,  1.5517e-01,\n",
       "         -1.6206e-03],\n",
       "        [-1.5499e-01,  3.4916e-01, -1.0239e-02,  1.5702e+00,  2.0533e-02,\n",
       "          7.7504e-01,  4.3553e-02, -3.4818e-01,  1.3345e+00,  1.0472e+00,\n",
       "          3.4267e-01,  1.1030e+00,  8.0169e-03,  3.4230e-02,  9.6021e-02,\n",
       "          5.4491e-01],\n",
       "        [-2.0536e-01, -1.0484e-02,  6.2879e-01,  8.3553e-01, -1.4406e-02,\n",
       "          1.1463e+00,  2.4830e-01, -7.5914e-01,  7.5223e-01,  1.5769e+00,\n",
       "         -7.3916e-02,  2.4655e-01,  5.7534e-04,  3.4806e-01,  2.1674e-01,\n",
       "          5.8474e-01],\n",
       "        [ 2.3003e-01,  9.1490e-01,  8.3032e-01,  3.1628e-02,  4.8140e-01,\n",
       "          1.0689e-02,  5.5390e-01,  2.1190e-01,  1.4193e-01,  2.0849e-02,\n",
       "         -1.0199e-01,  1.3143e-01,  6.4617e-03,  2.4844e-01, -1.5296e-01,\n",
       "         -1.3194e-02],\n",
       "        [ 3.7146e-01,  4.9008e-01,  1.1973e+00,  6.8392e-01, -1.7933e-02,\n",
       "          6.5248e-01,  4.4348e-02,  5.1590e-01,  4.9712e-01,  1.7845e-01,\n",
       "         -3.1937e-02,  9.6935e-01,  1.2214e-03,  1.9535e-01,  1.5775e-02,\n",
       "         -4.1113e-02],\n",
       "        [ 4.6876e-01,  8.8867e-01,  2.6050e-01,  6.7013e-01, -1.4107e-03,\n",
       "         -2.4062e-02,  1.2649e-01,  8.7281e-01, -4.3327e-02,  1.0613e-02,\n",
       "         -8.8038e-02,  1.1961e-02,  2.1831e-02,  8.5883e-02,  2.6305e-01,\n",
       "          8.1260e-02]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_unsigned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, you can also learn node feature representations induced by the edge signals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EIGNBlockMagneticEdgeLaplacianWithNodeTransformationConv(\n",
       "  (signed_fusion_layer): FusionLayer(\n",
       "    (lin_layer1): Linear(in_features=16, out_features=16, bias=False)\n",
       "    (lin_layer2): Linear(in_features=16, out_features=16, bias=False)\n",
       "  )\n",
       "  (unsigned_fusion_layer): FusionLayer(\n",
       "    (lin_layer1): Linear(in_features=16, out_features=16, bias=True)\n",
       "    (lin_layer2): Linear(in_features=16, out_features=16, bias=True)\n",
       "  )\n",
       "  (unsigned_conv): ResidualWrapper(\n",
       "    (lin): Linear(in_features=6, out_features=16, bias=False)\n",
       "    (conv): MagneticEdgeLaplacianWithNodeTransformationConv(\n",
       "      (lin): Linear(in_features=6, out_features=16, bias=False)\n",
       "      (node_feature_transformation): Sequential(\n",
       "        (0): ReLU()\n",
       "        (1): Linear(in_features=16, out_features=16, bias=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (unsigned_signed_conv): MagneticEdgeLaplacianWithNodeTransformationConv(\n",
       "    (lin): Linear(in_features=6, out_features=16, bias=False)\n",
       "    (node_feature_transformation): Sequential(\n",
       "      (0): ReLU()\n",
       "      (1): Linear(in_features=16, out_features=16, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (signed_conv): ResidualWrapper(\n",
       "    (lin): Linear(in_features=3, out_features=16, bias=False)\n",
       "    (conv): MagneticEdgeLaplacianWithNodeTransformationConv(\n",
       "      (lin): Linear(in_features=3, out_features=16, bias=False)\n",
       "      (node_feature_transformation): Sequential(\n",
       "        (0): ReLU()\n",
       "        (1): Linear(in_features=16, out_features=16, bias=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (signed_unsigned_conv): MagneticEdgeLaplacianWithNodeTransformationConv(\n",
       "    (lin): Linear(in_features=3, out_features=16, bias=False)\n",
       "    (node_feature_transformation): Sequential(\n",
       "      (0): ReLU()\n",
       "      (1): Linear(in_features=16, out_features=16, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "block = EIGNBlockMagneticEdgeLaplacianWithNodeTransformationConv(\n",
    "    num_signed_features,\n",
    "    num_signed_features_out,\n",
    "    num_unsigned_features,\n",
    "    num_unsigned_features_out,\n",
    "    q=1 / edge_index.size(1),\n",
    "    initialize_node_feature_transformation=lambda num_in, num_out: nn.Sequential(\n",
    "        nn.ReLU(), nn.Linear(num_in, num_out)\n",
    "    ),\n",
    ").eval()\n",
    "block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_signed, output_unsigned = block(\n",
    "    dummy_features_signed, dummy_features_unsigned, edge_index, edge_is_directed\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "magnetic_edge_gnn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
